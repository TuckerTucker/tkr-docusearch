# DocuSearch Environment Variables
# Copy this file to .env and configure with your values
# WARNING: Keep .env secure - it contains API keys and secrets!

# ============================================================================
# ASR Configuration - MLX Backend (Metal GPU Acceleration)
# ============================================================================
ASR_ENABLED=true
ASR_BACKEND=mlx
ASR_MODEL=turbo
ASR_LANGUAGE=en
ASR_WORD_TIMESTAMPS=true
ASR_TEMPERATURE=0.0
ASR_MAX_TIME_CHUNK=30.0
ASR_BATCH_SIZE=12

# ============================================================================
# HuggingFace Model Cache
# ============================================================================
# Directory for caching MLX Whisper and ColPali models
HF_HOME=/Volumes/tkr-riffic/@tkr-projects/tkr-docusearch/data/models

# ============================================================================
# Logging
# ============================================================================
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# ============================================================================
# LLM Configuration for Research Bot
# ============================================================================
# Provider: openai, anthropic, google, or local
LLM_PROVIDER=openai

# Model selection (provider-specific)
# OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
# Google: gemini-pro, gemini-ultra
LLM_MODEL=gpt-4

# ============================================================================
# LLM API Keys
# ============================================================================
# Set the API key(s) for the provider(s) you plan to use
# Get keys from:
# - OpenAI: https://platform.openai.com/api-keys
# - Anthropic: https://console.anthropic.com/
# - Google: https://makersuite.google.com/app/apikey

# OpenAI API Key
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API Key (for Claude models)
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Google API Key (for Gemini models)
# GOOGLE_API_KEY=your-google-api-key-here

# ============================================================================
# ChromaDB Configuration
# ============================================================================
CHROMA_HOST=localhost
CHROMA_PORT=8001

# ============================================================================
# Processing Worker Configuration
# ============================================================================
WORKER_PORT=8002
DEVICE=mps
# Options: mps (Metal), cuda (NVIDIA), cpu
MODEL_PRECISION=fp16
# Options: fp16, fp32

# ============================================================================
# Upload Configuration
# ============================================================================
UPLOAD_DIR=/uploads
MAX_FILE_SIZE_MB=100
SUPPORTED_FORMATS=pdf,docx,pptx,xlsx,html,xhtml,md,asciidoc,csv,mp3,wav,vtt,png,jpg,jpeg,tiff,bmp,webp

# ============================================================================
# CORS Configuration
# ============================================================================
# Comma-separated list of allowed origins for CORS
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000,http://localhost:8001,http://localhost:8002

# ============================================================================
# Copyparty Configuration
# ============================================================================
COPYPARTY_PORT=8000

# ============================================================================
# Research API Configuration
# ============================================================================
RESEARCH_API_PORT=8004

# ============================================================================
# Local LLM Preprocessing Configuration
# ============================================================================
# Enable local LLM preprocessing to reduce foundation model costs
# Requires: LLM_PROVIDER=mlx, MLX model downloaded

# Enable/disable preprocessing (default: false)
LOCAL_PREPROCESS_ENABLED=false

# Strategy: compress, filter, or synthesize (default: compress)
LOCAL_PREPROCESS_STRATEGY=compress

# Filtering threshold (0-10, default: 7.0)
LOCAL_PREPROCESS_THRESHOLD=7.0

# Maximum sources to retrieve before preprocessing (default: 20)
LOCAL_PREPROCESS_MAX_SOURCES=20
