# Project configuration for AI agents - tkr-context-kit
# Synthesized comprehensive context optimized for token efficiency
meta:
  kit: tkr-context-kit
  fmt: 1
  type: multimodal-document-search-system
  desc: "Local document processing and semantic search with ColNomic 7B, ChromaDB, copyparty, and multi-vector embeddings. Production-quality multi-agent orchestration for DocuSearch MVP."
  ver: "0.1.0"
  author: "Tucker github.com/tuckertucker"
  ts: "2025-10-06"
  status: wave-1-planning
  phase: "MVP Development - Wave 1 (Contract Definition)"
  entry: "docker-compose up"
  stack: &tech-stack "Python 3.10+ + ColPali (ColNomic 7B) + ChromaDB + Docling + copyparty + PyTorch MPS + Docker + Multi-Vector Embeddings + Two-Stage Search"
  cmds: ["docker-compose up", "scripts/setup.sh", "scripts/start.sh", "scripts/stop.sh"]
  achievements: ["Comprehensive 4-wave orchestration plan", "6-agent parallel development strategy", "Multi-vector embedding architecture", "Zero-conflict territorial ownership"]

# Dependencies - Python ML stack for document processing
deps: &deps
  py: &py-deps
    ml_core:
      colpali: &colpali {repo: "git+https://github.com/illuin-tech/colpali.git", desc: "ColQwen2_5 model class, not PyPI"}
      pytorch: {v: ">=2.0.0", desc: "MPS support for M1"}
      transformers: {v: ">=4.30.0"}
      pillow: {v: ">=10.0.0"}

    document_processing:
      docling: {v: ">=2.0.0", desc: "Document parsing"}
      pdf2image: {v: ">=1.16.0"}

    storage:
      chromadb: {v: ">=0.4.0", desc: "Vector database"}
      numpy: {v: ">=1.24.0"}

    web_server:
      copyparty: {v: "latest", desc: "File server with event hooks"}

    utilities:
      pydantic: {v: ">=2.0.0", desc: "Data validation"}
      python-dotenv: {v: ">=1.0.0"}

  docker: &docker-deps
    base:
      python: {v: "3.10-slim", platform: "linux/arm64"}
      chromadb-image: {v: "latest", platform: "linux/arm64"}

# Directory structure - Early stage project
struct:
  _: {n: 31757, t: {py: 0, md: 42, yml: 8, yaml: 5, sh: 26, json: 3}, status: "directories_created"}

  .claude:
    _: {n: 39, t: {md: 32, json: 3, sh: 2}}
    agents: {n: 25, desc: "Specialized AI agents including DocuSearch orchestration agents"}
    commands: {n: 13, desc: "Custom commands including /kg-orchestrate"}
    hooks: {files: [hooks.sh]}
    settings.local.json: tracked

  .context-kit:
    _: {n: 31684, t: {md: 8, yml: 8, yaml: 5}}
    _context-kit.yml: tracked

    orchestration:
      docusearch-mvp:
        _: {desc: "Comprehensive 4-wave orchestration plan for 6 parallel agents"}
        files:
          - orchestration-plan.md
          - agent-assignments.md
          - validation-strategy.md
          - coordination-protocol.md
          - README.md
        integration-contracts:
          _: {desc: "API interface specifications for agent integration"}
          files:
            - storage-interface.md
            - embedding-interface.md
            - processing-interface.md
            - search-interface.md
            - config-interface.md
            - ui-interface.md
        status: {desc: "Agent status updates directory (TBD)"}
        reviews: {desc: "Code review directory (TBD)"}
        blockers: {desc: "Active blocker tracking (TBD)"}
        test-results: {desc: "Integration test reports (TBD)"}

    _ref:
      _: {n: 31500, desc: "Reference documentation and ChromaDB source"}
      files:
        - ARCHITECTURE_SUMMARY.md
        - mvp-architecture.md
      packages:
        chroma: {desc: "ChromaDB source for reference"}
      context-kit: {desc: "Toolkit documentation"}

    _specs: {desc: "Specification documents"}

    analysis:
      _: {desc: "Analysis outputs and templates"}
      reports: empty
      templates: empty

    # Inherited from tkr-context-kit (not active for DocuSearch)
    core: {desc: "Shared TypeScript types (inherited, not used)"}
    dashboard: {desc: "React dashboard (inherited, not used)"}
    knowledge-graph: {desc: "Knowledge graph API (inherited, not used)"}
    logging-client: {desc: "Logging ecosystem (inherited, not used)"}
    mcp: {desc: "MCP integration (inherited, not used)"}

  docker:
    _: {n: 0, status: "to_be_created", owner: "infrastructure-agent"}
    planned_files:
      - docker-compose.yml
      - Dockerfile.copyparty
      - Dockerfile.processing-worker
      - .env

  scripts:
    _: {n: 0, status: "to_be_created", owner: "infrastructure-agent"}
    planned_files:
      - setup.sh
      - start.sh
      - stop.sh

  src:
    _: {n: 0, status: "directories_created"}

    storage:
      owner: storage-agent
      status: to_be_implemented
      planned_files:
        - __init__.py
        - chroma_client.py
        - collection_manager.py
        - compression.py
        - test_storage.py

    embeddings:
      owner: embedding-agent
      status: to_be_implemented
      planned_files:
        - __init__.py
        - colpali_wrapper.py
        - model_loader.py
        - scoring.py
        - test_embeddings.py

    processing:
      owner: processing-agent
      status: to_be_implemented
      planned_files:
        - __init__.py
        - processor.py
        - worker.py
        - docling_parser.py
        - visual_processor.py
        - text_processor.py
        - queue_manager.py
        - test_processing.py

    search:
      owner: search-agent
      status: to_be_implemented
      planned_files:
        - __init__.py
        - search_engine.py
        - result_ranker.py
        - query_processor.py
        - test_search.py

    ui:
      owner: ui-agent
      status: to_be_implemented
      planned_files:
        - search.html
        - search.js
        - status_dashboard.html
        - status_dashboard.js
        - styles.css

  data:
    _: {n: 0, status: "directories_created"}

    copyparty:
      owner: ui-agent
      hooks:
        planned: [on_upload.py]
      www: {desc: "Symlink to src/ui/"}

    chroma_db: {desc: "ChromaDB persistence"}
    models: {desc: "ColNomic 7B model cache (14GB)"}
    logs: {desc: "Application logs"}

  tests:
    _: {n: 0, status: "directories_created"}
    e2e: empty
    integration: empty
    performance: empty

  claude.local.md: tracked

# Multi-vector embedding architecture
arch:
  stack:
    <<: *tech-stack
    architecture: "Multi-vector embedding with two-stage search, event-driven processing, Docker orchestration, 6-agent parallel development"
    components: ["ColPali Engine", "ChromaDB Storage", "Document Processor", "Two-Stage Search", "copyparty UI", "Processing Worker"]
    lang: "Python 3.10+"
    runtime: "Docker containers with PyTorch MPS (M1 GPU)"
    persistence: "ChromaDB with multi-vector metadata storage"
    embedding_model: "ColNomic 7B (ColQwen2_5)"
    deployment: "3-container Docker Compose on M1 MacBook Pro"

  patterns: &arch-patterns
    - "Multi-vector embeddings with representative vectors + full sequences"
    - "Two-stage search: fast retrieval + late interaction re-ranking"
    - "Event-driven processing via copyparty hooks"
    - "Hybrid processing: visual (page images) + text (chunks)"
    - "Territorial ownership with zero-conflict development"
    - "Interface-first with integration contracts"
    - "Progressive validation with wave gates"
    - "FP16/INT8 quantization for memory efficiency"

  containers:
    copyparty:
      type: "Python 3.11 web server"
      port: 8000
      responsibility: "File upload/browsing, search UI, event hooks"
      features: ["Web UI", "Upload handling", "Event triggers", "Search interface"]
      volumes: ["./data/copyparty:/data", "./src/ui:/www"]

    processing-worker:
      type: "Python 3.10 ML worker"
      responsibility: "Document processing with ColPali embeddings"
      features: ["Docling parsing", "Visual processing", "Text chunking", "Embedding generation", "ChromaDB storage"]
      volumes: ["./data/copyparty/uploads:/uploads", "./data/models:/models", "./data/logs:/logs"]
      environment:
        PYTORCH_ENABLE_MPS_FALLBACK: "1"
        MODEL_CACHE: "/models"
        CHROMA_HOST: "chromadb"
        CHROMA_PORT: "8001"

    chromadb:
      type: "ChromaDB vector database"
      port: 8001
      responsibility: "Vector storage and similarity search"
      features: ["HNSW indexing", "Multi-vector metadata", "HTTP API"]
      volumes: ["./data/chroma_db:/chroma/chroma"]

  embedding_strategy:
    model: "ColNomic 7B (nomic-ai/colnomic-embed-multimodal-7b)"
    architecture: "ColBERT-style multi-vector embeddings"
    output_shape: "(seq_length, 768) per document/chunk"

    storage_format:
      representative_vector:
        source: "CLS token (first vector)"
        shape: "(768,)"
        usage: "Fast initial retrieval in ChromaDB HNSW index"

      full_sequence:
        source: "All output vectors"
        shape: "(seq_length, 768)"
        storage: "Compressed (gzip) + base64 in ChromaDB metadata"
        usage: "Late interaction re-ranking with MaxSim"

    quantization:
      fp16: {memory: "14GB", quality: "100%", speed: "6s/page"}
      int8: {memory: "7GB", quality: "90-95%", speed: "3s/page", recommended_for: "8GB Macs"}

  search_pipeline:
    stage_1_retrieval:
      method: "ChromaDB HNSW search on representative vectors"
      input: "Query CLS token"
      output: "Top-100 candidates"
      latency: "~200ms"

    stage_2_reranking:
      method: "Late interaction MaxSim scoring"
      input: "Query full sequence + candidate full sequences"
      output: "Top-10 results"
      latency: "~100ms"
      algorithm: "processor.score_multi_vector()"

    total_latency: "<500ms target (300ms typical)"

  processing_workflow:
    visual_branch:
      input: "PDF/DOCX/PPTX pages"
      steps: ["Render to images", "ColPali embed_images()", "Store in visual_collection"]
      storage_per_page: "78KB (3KB CLS + 75KB compressed sequence)"

    text_branch:
      input: "Extracted text"
      steps: ["Chunk (~250 words)", "ColPali embed_text()", "Store in text_collection"]
      storage_per_chunk: "51KB (3KB CLS + 48KB compressed sequence)"

    hybrid: "Both branches processed in parallel"

# Agent orchestration system
agents:
  orchestration:
    plan: ".context-kit/orchestration/docusearch-mvp/orchestration-plan.md"
    assignments: ".context-kit/orchestration/docusearch-mvp/agent-assignments.md"
    validation: ".context-kit/orchestration/docusearch-mvp/validation-strategy.md"
    protocol: ".context-kit/orchestration/docusearch-mvp/coordination-protocol.md"
    total_agents: 6
    execution_waves: 4
    timeline: "2-3 weeks"

  wave_1_foundation:
    duration: "Days 1-2"
    objective: "Establish infrastructure and define all integration contracts"
    agents: [infrastructure-agent, storage-agent, embedding-agent, processing-agent, search-agent, ui-agent]
    deliverables:
      - "Docker environment with 3 containers"
      - "6 integration contract documents"
      - "Project directory structure"
      - "M1 compatibility validation"
    gate_criteria:
      - "All contracts reviewed and approved"
      - "Docker builds successfully on ARM64"
      - "PyTorch MPS available in container"
      - "ColNomic 7B model cached (14GB)"

  wave_2_components:
    duration: "Days 3-7"
    objective: "Implement independent components with contract compliance"
    agents: [infrastructure-agent, storage-agent, embedding-agent, processing-agent, search-agent, ui-agent]
    parallelism: "All agents work independently with mocks"
    deliverables:
      - "Working Docker environment"
      - "ChromaClient with multi-vector storage"
      - "ColPaliEngine with embedding + scoring"
      - "DocumentProcessor with mocks"
      - "SearchEngine with two-stage pipeline"
      - "Search UI with event hooks"
    gate_criteria:
      - "Unit tests pass (>90% coverage)"
      - "Mock interfaces match contracts"
      - "ColNomic 7B loads with MPS"
      - "Code reviews approved"

  wave_3_integration:
    duration: "Days 8-12"
    objective: "Replace mocks with real integrations, test full workflows"
    agents: [processing-agent, search-agent, ui-agent, infrastructure-agent]
    deliverables:
      - "End-to-end processing pipeline"
      - "Fully functional two-stage search"
      - "Complete user workflow (upload → search)"
      - "Production-ready Docker orchestration"
    gate_criteria:
      - "End-to-end visual search works"
      - "10-page PDF processes in <2min"
      - "Search returns relevant results (<500ms)"
      - "Integration tests pass"

  wave_4_production:
    duration: "Days 13-15"
    objective: "Add production features, optimize performance, validate scalability"
    agents: [search-agent, ui-agent, processing-agent]
    deliverables:
      - "Search filters and pagination"
      - "Polished UI with dashboard"
      - "Scalable processing queue"
    gate_criteria:
      - "100 document batch test passes"
      - "Search latency <500ms p95"
      - "Processing speed meets targets"
      - "User acceptance test passed"

  agent_roster:
    infrastructure-agent:
      specialization: "Docker orchestration, DevOps"
      owned_dirs: ["docker/", "scripts/"]
      responsibilities:
        - "Docker Compose with 3 services"
        - "Container networking and volumes"
        - "Health checks and resource limits"
        - "M1-specific optimizations"
        - "Setup and startup scripts"
      critical_tasks:
        - "Pre-download ColNomic 7B (14GB)"
        - "Verify PyTorch MPS in container"
        - "Configure volume mounts"

    storage-agent:
      specialization: "ChromaDB integration"
      owned_dirs: ["src/storage/"]
      responsibilities:
        - "ChromaDB client wrapper"
        - "Collection initialization"
        - "Multi-vector storage (CLS + metadata)"
        - "Compression/decompression"
        - "Metadata validation"
      critical_tasks:
        - "Implement gzip compression for embeddings"
        - "Handle ChromaDB metadata size limits"
        - "Support filtering in search"

    embedding-agent:
      specialization: "ColPali engine"
      owned_dirs: ["src/embeddings/"]
      responsibilities:
        - "ColQwen2_5 model loading"
        - "Image embedding generation"
        - "Text embedding generation"
        - "Late interaction scoring (MaxSim)"
        - "FP16/INT8 quantization"
      critical_tasks:
        - "Load model with MPS device mapping"
        - "Implement score_multi_vector() API"
        - "Handle device fallback (MPS → CPU)"

    processing-agent:
      specialization: "Document processing"
      owned_dirs: ["src/processing/"]
      responsibilities:
        - "Docling parser integration"
        - "Visual processing pipeline"
        - "Text processing pipeline"
        - "Hybrid workflow coordination"
        - "Processing worker daemon"
      critical_tasks:
        - "Render PDF pages to images"
        - "Chunk text efficiently (~250 words)"
        - "Integrate embedding + storage APIs"

    search-agent:
      specialization: "Semantic search"
      owned_dirs: ["src/search/"]
      responsibilities:
        - "Two-stage search implementation"
        - "Result merging (visual + text)"
        - "Result ranking (MaxSim scores)"
        - "Filter application"
        - "Search metrics"
      critical_tasks:
        - "Implement Stage 1 retrieval"
        - "Implement Stage 2 re-ranking"
        - "Optimize latency (<500ms)"

    ui-agent:
      specialization: "Web UI, event hooks"
      owned_dirs: ["src/ui/", "data/copyparty/"]
      responsibilities:
        - "Search page (HTML/JS/CSS)"
        - "Query form with validation"
        - "Results display"
        - "copyparty event hooks"
        - "Status dashboard"
      critical_tasks:
        - "Connect to search API"
        - "Implement on_upload.py hook"
        - "Add real-time status polling"

  territorial_ownership:
    principle: "Zero overlapping file writes"
    conflict_prevention:
      - "Exclusive write access per agent"
      - "Integration via documented contracts"
      - "Mock-first development until Wave 3"
      - "Code review gate before integration"

  communication:
    status_updates:
      frequency: "Daily (end of day)"
      format: "JSON in .context-kit/orchestration/docusearch-mvp/status/"
      required_fields: [agent, wave, status, task, timestamp, deliverables, blockers]

    code_reviews:
      timing: "Wave 2 → Wave 3 transition"
      process: "Consumer reviews provider API, validates contract"
      approval_required: true

    blocker_resolution:
      reporting: "Immediate via blockers/ directory"
      escalation: "24 hours without resolution"
      format: "Markdown with problem, solution, timeline"

# Operational patterns
ops:
  paths: &key-paths
    ".claude/": "Claude Code configuration and agents"
    ".context-kit/orchestration/": "DocuSearch MVP orchestration plan"
    "docker/": "Docker Compose and Dockerfiles"
    "scripts/": "Setup and utility scripts"
    "src/": "Python source code (5 modules)"
    "data/": "Data directories (copyparty, chromadb, models, logs)"
    "tests/": "Test suites (e2e, integration, performance)"

  development_patterns:
    docker_workflow: "docker-compose up -d → docker logs -f processing-worker"
    model_cache: "Pre-download to data/models/ to avoid repeated downloads"
    testing_strategy: "Unit tests (Wave 2) → Integration tests (Wave 3) → E2E tests (Wave 4)"

  deployment_patterns:
    setup: "./scripts/setup.sh initializes directories and downloads models"
    start: "./scripts/start.sh orchestrates Docker Compose startup"
    stop: "./scripts/stop.sh graceful shutdown"
    health_check: "Docker container health checks"

  performance_targets:
    processing:
      fp16: "6s/page (14GB memory)"
      int8: "3s/page (7GB memory)"
      batch: "100 PDFs in <2 hours (FP16) or <1 hour (INT8)"

    search:
      simple_query: "230ms"
      visual_query: "300ms"
      hybrid_query: "320ms"
      p95_target: "<500ms"

    storage:
      efficiency: "<3x original file size"
      per_page: "78KB (visual) + 51KB (text chunk)"
      100_pdfs: "~678MB (2,000 pages + 6,000 chunks)"
      1000_pdfs: "~6.78GB"

  risk_mitigation:
    high_risk:
      m1_compatibility:
        risk: "PyTorch MPS not available in Docker"
        mitigation: "Test in Wave 2, fallback to CPU"
        validation: "torch.backends.mps.is_available() returns True"

      model_download:
        risk: "ColNomic 7B timeout (14GB)"
        mitigation: "Pre-cache in setup script"
        validation: "Model loads in <30s from cache"

      multi_vector_storage:
        risk: "ChromaDB metadata size limits"
        mitigation: "Test with real embeddings, implement compression"
        validation: "Store 100-token sequence successfully"

      memory_overflow:
        risk: "ColNomic 7B crashes with 8GB RAM"
        mitigation: "Implement INT8 quantization"
        validation: "Container stays under 8GB limit"

    medium_risk:
      search_performance:
        risk: "Late interaction too slow"
        mitigation: "Profile and optimize MaxSim"
        validation: "Two-stage search <500ms"

      processing_backlog:
        risk: "100 document upload creates backlog"
        mitigation: "Implement queue in Wave 4"
        validation: "Queue drains within target time"

# Integration contracts (summary)
contracts:
  storage_interface:
    file: "integration-contracts/storage-interface.md"
    provider: storage-agent
    consumers: [processing-agent, search-agent]
    key_methods:
      - "ChromaClient.add_embeddings(collection, embeddings, metadata)"
      - "ChromaClient.search(collection, query_embedding, n_results, filters)"
      - "ChromaClient.create_collection(name, metadata_schema)"

  embedding_interface:
    file: "integration-contracts/embedding-interface.md"
    provider: embedding-agent
    consumers: [processing-agent, search-agent]
    key_methods:
      - "ColPaliEngine.embed_images(images) → (seq_length, 768)"
      - "ColPaliEngine.embed_text(texts) → (seq_length, 768)"
      - "ColPaliEngine.score_multi_vector(query, candidates) → scores"

  processing_interface:
    file: "integration-contracts/processing-interface.md"
    provider: processing-agent
    consumers: [ui-agent]
    key_methods:
      - "DocumentProcessor.process_document(file_path)"
      - "Worker event hook trigger format"
      - "Processing status messages"

  search_interface:
    file: "integration-contracts/search-interface.md"
    provider: search-agent
    consumers: [ui-agent]
    key_methods:
      - "SearchEngine.query(query_text, mode, filters) → results"
      - "Two-stage pipeline specification"
      - "Result format with scores and metadata"

  config_interface:
    file: "integration-contracts/config-interface.md"
    provider: infrastructure-agent
    consumers: [all agents]
    environment_variables:
      - "MODEL_CACHE=/models"
      - "CHROMA_HOST=chromadb"
      - "CHROMA_PORT=8001"
      - "PYTORCH_ENABLE_MPS_FALLBACK=1"

# Validation strategy
validation:
  wave_1_to_wave_2:
    - "All contracts reviewed and approved"
    - "Docker builds successfully on ARM64"
    - "Directory structure matches territorial assignments"
    - "No overlapping file ownership conflicts"

  wave_2_to_wave_3:
    - "All unit tests pass (>90% coverage)"
    - "Mock interfaces match contracts exactly"
    - "Docker environment runs without errors"
    - "ColNomic 7B loads with MPS"
    - "Code reviews approved"

  wave_3_to_wave_4:
    - "End-to-end visual search works"
    - "ChromaDB contains valid embeddings"
    - "Two-stage search <500ms"
    - "UI shows results with thumbnails"
    - "Processing worker handles errors"
    - "Integration tests pass"

  wave_4_to_production:
    - "100 document batch test passes"
    - "Search latency <500ms p95"
    - "Processing speed meets targets"
    - "Storage efficiency <3x original"
    - "User acceptance test passed"
    - "Documentation complete"

# Semantic context for AI consumption
semantic:
  ~multimodal_embeddings: "ColNomic 7B produces multi-vector embeddings for visual + text"
  ~two_stage_search: "Fast retrieval with CLS token, precise re-ranking with late interaction"
  ~event_driven_processing: "copyparty triggers processing on upload"
  ~territorial_ownership: "Zero-conflict development with exclusive write access"
  ~interface_first: "Integration contracts define APIs before implementation"
  ~progressive_validation: "Quality gates between waves ensure integration success"
  ~m1_optimized: "PyTorch MPS acceleration, ARM64 Docker images"
  ~production_quality: "Full multi-vector storage from MVP, no re-architecting needed"
  ~agent_orchestration: "6 specialized agents, 4-wave execution, 2-3 week timeline"
  ~hybrid_processing: "Parallel visual (page images) + text (chunks) workflows"

# Architecture evolution notes
notes:
  # Format version 1 (2025-10-06)
  - "PROJECT INITIALIZATION: DocuSearch MVP with comprehensive orchestration plan"
  - "6-AGENT ARCHITECTURE: infrastructure, storage, embedding, processing, search, ui"
  - "4-WAVE EXECUTION: Foundation → Components → Integration → Production"
  - "MULTI-VECTOR STORAGE: Production-quality from day one, no simplified prototyping"
  - "COLNOMIC 7B: State-of-the-art multimodal embeddings (Vidore-v2 benchmark leader)"
  - "TWO-STAGE SEARCH: 200ms retrieval + 100ms re-ranking = <500ms total"
  - "M1 OPTIMIZATION: PyTorch MPS, ARM64 Docker, INT8 quantization for 8GB Macs"
  - "ZERO-CONFLICT DEVELOPMENT: Territorial ownership prevents merge conflicts"
  - "INTEGRATION CONTRACTS: API-first development with documented interfaces"
  - "COMPREHENSIVE VALIDATION: Progressive gates ensure quality at each wave"

  # Project status
  - "CURRENT WAVE: Wave 1 (Contract Definition)"
  - "DIRECTORIES CREATED: src/, data/, tests/, docker/, scripts/"
  - "ORCHESTRATION DOCS: Complete (plan, assignments, validation, protocol)"
  - "NEXT STEPS: Review contracts, assign team members, kickoff Wave 1"

  # Key innovations
  - "Production-quality multi-vector architecture from MVP"
  - "Comprehensive parallel agent orchestration"
  - "M1-optimized deployment strategy"
  - "Event-driven processing with copyparty"
  - "Hybrid visual + text processing"
